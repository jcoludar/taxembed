# Hierarchical Taxonomy Embeddings with Poincar√© Geometry

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Learn hierarchical embeddings of NCBI's biological taxonomy in hyperbolic space.**

This project extends Facebook Research's Poincar√© embeddings with hierarchical features specifically designed for deep taxonomic hierarchies (38 levels, 2.7M organisms).

---

## ‚ú® Features

- **Hyperbolic Geometry**: Embeddings in Poincar√© ball model (ideal for hierarchies)
- **Transitive Closure Training**: 975K ancestor-descendant pairs (not just parent-child)
- **Depth-Aware Features**: Initialization, regularization, and weighting by taxonomic depth
- **Hard Negative Sampling**: Cousin sampling at same depth level
- **Ball Constraint Enforcement**: 3-layer strategy ensures 100% valid embeddings
- **Performance Optimized**: 1000x faster regularizer, selective projection
- **Comprehensive Validation**: Automated sanity checks and quality metrics

---

## üöÄ Quick Start

### **Installation**

```bash
# Clone the repository
git clone https://github.com/jcoludar/taxembed.git
cd taxembed

# Create virtual environment
python3.11 -m venv venv311
source venv311/bin/activate  # or venv311\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

### **Download Data**

```bash
# Download and prepare NCBI taxonomy
python prepare_taxonomy_data.py

# This creates:
# - data/taxonomy_edges_small.edgelist (111K organisms)
# - data/taxonomy_edges.edgelist (2.7M organisms)
# - data/nodes.dmp, names.dmp (NCBI taxonomy files)
```

### **Train Model (Small Dataset)**

```bash
# Build transitive closure (ancestor-descendant pairs)
python build_transitive_closure.py

# Train hierarchical model
bash run_hierarchical_training.sh

# Or with custom parameters:
python train_hierarchical.py \
    --data data/taxonomy_edges_small_transitive.pkl \
    --checkpoint my_model.pth \
    --dim 10 \
    --epochs 100 \
    --early-stopping 10 \
    --lr 0.005 \
    --lambda-reg 0.1
```

### **Analyze Results**

```bash
# Check hierarchy quality
python analyze_hierarchy_hyperbolic.py

# Visualize embeddings
python scripts/visualize_embeddings.py my_model.pth --highlight mammals
```

---

## üìä What's Different from Facebook's Implementation?

| Feature | Facebook | This Project |
|---------|----------|--------------|
| **Training Data** | Parent-child only | All ancestor-descendant pairs (9.8x more) |
| **Initialization** | Random | Depth-aware (root near center, leaves near boundary) |
| **Regularization** | None | Radial penalty to enforce depth ‚Üí radius mapping |
| **Negative Sampling** | Random | Hard negatives (cousins at same taxonomic level) |
| **Loss Weighting** | Uniform | Depth-weighted (deeper pairs more important) |
| **Ball Constraints** | Soft projection | 3-layer enforcement (100% compliance) |
| **Performance** | Baseline | 1000x faster regularizer, 30x faster projection |

---

## üìÅ Project Structure

```
poincare-embeddings/
‚îú‚îÄ‚îÄ train_hierarchical.py          # Main hierarchical training script
‚îú‚îÄ‚îÄ build_transitive_closure.py    # Generate ancestor-descendant pairs
‚îú‚îÄ‚îÄ analyze_hierarchy_hyperbolic.py # Evaluate hierarchy quality
‚îú‚îÄ‚îÄ sanity_check.py                 # Comprehensive validation
‚îú‚îÄ‚îÄ prepare_taxonomy_data.py        # Download NCBI taxonomy
‚îú‚îÄ‚îÄ remap_edges.py                  # Map TaxIDs to indices
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Data files (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ taxonomy_edges_small.edgelist
‚îÇ   ‚îú‚îÄ‚îÄ taxonomy_edges_small_transitive.pkl
‚îÇ   ‚îî‚îÄ‚îÄ taxonomy_edges_small.mapping.tsv
‚îÇ
‚îú‚îÄ‚îÄ scripts/                        # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ visualize_embeddings.py
‚îÇ   ‚îú‚îÄ‚îÄ validate_data.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ hype/                           # Original Facebook implementation
‚îÇ   ‚îú‚îÄ‚îÄ graph.py
‚îÇ   ‚îú‚îÄ‚îÄ manifolds/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ docs/                           # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ archive/                    # Intermediate development docs
‚îÇ
‚îú‚îÄ‚îÄ JOURNEY.md                      # Development history
‚îú‚îÄ‚îÄ QUICKSTART.md                   # 5-minute guide
‚îî‚îÄ‚îÄ README.md                       # This file
```

---

## üéØ Current Status

### **What Works ‚úÖ**
- ‚úÖ Clean data pipeline with validation
- ‚úÖ Transitive closure computation (975K pairs)
- ‚úÖ Hierarchical training features implemented
- ‚úÖ Perfect ball constraint enforcement (100% inside)
- ‚úÖ Stable training (~3 min/epoch on M3 Mac CPU)
- ‚úÖ Automatic checkpointing and early stopping

### **What Needs Work ‚ö†Ô∏è**
- ‚ö†Ô∏è Hierarchy quality is poor after limited training (2 epochs)
- ‚ö†Ô∏è Depth-norm correlation ~0 (should be >0.5)
- ‚ö†Ô∏è Taxonomic separation ratios <1.1x (should be >1.5x)
- ‚ö†Ô∏è Needs hyperparameter tuning or longer training

**See [JOURNEY.md](JOURNEY.md) for full development history and current challenges.**

---

## üîß Key Scripts

### **Training**
```bash
# Hierarchical training with all features
python train_hierarchical.py --help

# Simple training (Facebook's original)
python embed.py -dset data/taxonomy_edges.mapped.edgelist ...
```

### **Analysis**
```bash
# Validate data quality
python sanity_check.py

# Check hierarchy quality
python analyze_hierarchy_hyperbolic.py

# Visualize specific groups
python scripts/visualize_embeddings.py model.pth --highlight primates
```

### **Data Preparation**
```bash
# Download NCBI taxonomy
python prepare_taxonomy_data.py

# Build transitive closure
python build_transitive_closure.py

# Validate data
python scripts/validate_data.py small
```

---

## üìñ Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Get started in 5 minutes
- **[JOURNEY.md](JOURNEY.md)** - Full development history from Facebook's code to now
- **[SESSION_SUMMARY_NOV8.md](SESSION_SUMMARY_NOV8.md)** - Latest session summary with findings
- **[docs/archive/](docs/archive/)** - Intermediate development documents

---

## üß™ Validation

Before training, run the comprehensive sanity check:

```bash
python sanity_check.py
```

This validates:
- ‚úÖ Mapping file integrity (no duplicates, continuous indices)
- ‚úÖ Transitive closure data (valid indices, no self-loops)
- ‚úÖ Projection logic (keeps embeddings in ball)
- ‚úÖ Hyperbolic distance (correct formula)
- ‚úÖ Initialization (proper depth-based radii)
- ‚úÖ Sibling map (hard negatives at same depth)
- ‚úÖ Regularizer targets (all < 1.0)
- ‚úÖ Training configuration (reasonable batch sizes)

**Expected: 10/10 checks passed**

---

## üìà Performance

### **Optimizations Applied**
- **Regularizer**: Vectorized (1000x faster, 1.7B ‚Üí 111K ops/epoch)
- **Projection**: Selective (30x faster, only updated embeddings)
- **Tensor Creation**: Pre-allocated arrays (10-100x faster)
- **Device**: CPU-only on macOS (stable, no MPS hanging)

### **Training Speed**
- Small dataset (111K organisms): ~3 min/epoch on M3 Mac
- Full dataset (2.7M organisms): ~60 min/epoch on M3 Mac

---

## üî¨ Experimental Results

### **Ball Constraint Enforcement**
| Version | Max Norm | Outside Ball | Status |
|---------|----------|--------------|--------|
| v1 (weak reg) | 2.18 | 54% | ‚ùå Broken |
| v2 (strong reg) | 1.45 | 2.2% | ‚ö†Ô∏è Better |
| v3 (3-layer) | 1.00 | 0% | ‚úÖ Perfect |

### **Hierarchy Quality** (After 2 epochs)
| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Depth-norm corr | >0.5 | +0.003 | ‚ùå Poor |
| Phylum sep | >1.5x | 1.08x | ‚ùå Poor |
| Class sep | >1.5x | 0.99x | ‚ùå Poor |

**Conclusion:** Constraints work perfectly, but hierarchy learning needs more time or tuning.

---

## üöß Known Issues & Future Work

### **Current Limitations**
1. **Poor hierarchy quality** - Only 2 epochs completed, needs more training
2. **Data imbalance** - 94% deep ancestors, 6% parent-child (may need balanced sampling)
3. **Regularization trade-off** - Œª=0.1 enforces constraints but may limit expressiveness
4. **No curriculum learning** - Trains on all pairs at once (may need progressive training)

### **Future Directions**
1. Train longer with increased patience (50-100 epochs)
2. Implement balanced sampling (equal parent-child, grandparent, deep)
3. Progressive training (parent-child ‚Üí grandparent ‚Üí all ancestors)
4. Try Riemannian optimizer (respects manifold natively)
5. Experiment with margin schedules (increase margin with depth)

---

## ü§ù Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### **Priority Areas**
- Hyperparameter tuning for better hierarchy quality
- Balanced/curriculum sampling strategies
- Alternative hyperbolic models (Lorentz, Klein)
- Evaluation metrics for taxonomic hierarchies
- Scalability to full 2.7M organism dataset

---

## üìö References

### **Original Papers**
- Nickel & Kiela (2017). "Poincar√© Embeddings for Learning Hierarchical Representations" [[PDF](https://arxiv.org/abs/1705.08039)]
- Facebook Research implementation: [[GitHub](https://github.com/facebookresearch/poincare-embeddings)]

### **Data**
- NCBI Taxonomy: https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/
- Taxonomy documentation: https://www.ncbi.nlm.nih.gov/taxonomy

### **Related Work**
- Hyperbolic Neural Networks
- Lorentz Embeddings
- Box Embeddings for Hierarchies

---

## üìú License

MIT License - see [LICENSE](LICENSE) file for details.

---

## üë• Authors

- Based on Facebook Research's Poincar√© embeddings
- Extended for hierarchical taxonomy by @jcoludar
- Development history in [JOURNEY.md](JOURNEY.md)

---

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/jcoludar/taxembed/issues)
- **Documentation**: See [JOURNEY.md](JOURNEY.md) and [docs/](docs/)
- **Quick Help**: See [QUICKSTART.md](QUICKSTART.md)

---

**‚≠ê If you find this useful, please star the repository!**

*Last Updated: November 8, 2025*
